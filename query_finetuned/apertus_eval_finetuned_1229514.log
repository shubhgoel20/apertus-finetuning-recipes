Job started on nid006692 at Sat 13 Dec 2025 12:35:03 AM CET
Working directory: /users/mmeciani/scratch/apertus-project/apertus-finetuning-recipes/query_finetuned
HF_HOME set to: /users/mmeciani/scratch/apertus-project/huggingface_cache
Python interpreter: /iopsstor/scratch/cscs/mmeciani/apertus-project/.venv/bin/python
Running fine-tuned model evaluation...
--- Starting Inference for /users/mmeciani/scratch/apertus-project/huggingface_cache/models--swiss-ai--Apertus-8B-Instruct-2509/snapshots/cdb3e4f4ad41e0cc394bb92c302ac2eed57e9586 ---
CUDA Available: True
CUDA Device Name: NVIDIA GH200 120GB
CUDA Device Count: 4
HF_HOME environment variable: /users/mmeciani/scratch/apertus-project/huggingface_cache
HF_HUB_OFFLINE environment variable: 1
Transformers version: 4.57.3
Loading tokenizer from /users/mmeciani/scratch/apertus-project/huggingface_cache/models--swiss-ai--Apertus-8B-Instruct-2509/snapshots/cdb3e4f4ad41e0cc394bb92c302ac2eed57e9586...
Loading model from /users/mmeciani/scratch/apertus-project/huggingface_cache/models--swiss-ai--Apertus-8B-Instruct-2509/snapshots/cdb3e4f4ad41e0cc394bb92c302ac2eed57e9586 (device_map='auto', torch_dtype=bfloat16)...
Model loaded on device: cuda:0
Model dtype: torch.bfloat16
Loading LoRA adapter from /users/mmeciani/scratch/apertus-project/output...
âœ… Fine-tuned model loaded successfully!
=== example 0 ===
correct: 1
total: 1
accuracy: 1.0
correct: 19
total: 100
accuracy: 0.19
Evaluation finished.
Job ended at Sat 13 Dec 2025 12:48:49 AM CET
